{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db28ac9e",
   "metadata": {},
   "source": [
    "# üìì Human Activity Classification from Sensor Data\n",
    "\n",
    "### Instructions for Participants\n",
    "\n",
    "- All necessary code is already provided.  \n",
    "- You should **not need to write new functions** unless you want to experiment.  \n",
    "- Your tasks: tweak parameters, run experiments, interpret results, and answer the reflection prompts in markdown.  \n",
    "- Use the dataset ‚Äúmovement_dataset_windows.csv‚Äù (or raw logs) to proceed.\n",
    "\n",
    "### Misc\n",
    "\n",
    "This exercise is based on: https://github.com/mattiasahle/DT374B_Machine_Learning_and_Data_Acquisition/tree/master\n",
    "\n",
    "Jupyter Notebook in VSCode: https://code.visualstudio.com/docs/datascience/jupyter-notebooks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e177a74a",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- Regenerate this file to add:\n",
    "    - More different ML algos\n",
    "    - More extplanations (the why) surrounding the code\n",
    "- Add mock dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856398cd",
   "metadata": {},
   "source": [
    "## Pre-reqs\n",
    "\n",
    "`pip install numpy pandas matplotlib seaborn scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e613a",
   "metadata": {},
   "source": [
    "## üèÅ Step 0: Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d376084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human Activity Classification from Sensor Datae\n",
    "# Description: Classify human activities (jump, run, walk, pushup) from accelerometer, gyroscope and magnetometer recordings.\n",
    "\n",
    "# ---\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "DATA_PATH = \"./data\"  # Change this if your data folder is elsewhere\n",
    "ACTIVITIES = ['jump', 'run', 'walk', 'pushup']\n",
    "SENSORS = ['acc', 'gyro', 'mag']\n",
    "RECORDINGS = [1, 2, 3, 4, 5, 6]  # 6 recordings per activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4fe2f5",
   "metadata": {},
   "source": [
    "## üì• Step 1: Load and Visualize Example Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sensor_file(activity, sensor, recording_num):\n",
    "    \"\"\"Loads a single sensor CSV file and returns a DataFrame.\"\"\"\n",
    "    filename = f\"{activity}_{sensor}{recording_num}.csv\"\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['Activity'] = activity\n",
    "    df['Sensor'] = sensor\n",
    "    df['Recording'] = recording_num\n",
    "    return df\n",
    "\n",
    "# Example: Visualize Jumping accelerometer data (recording 1)\n",
    "example_df = load_sensor_file('jump', 'acc', 1)\n",
    "\n",
    "# Plot signal\n",
    "plt.plot(example_df['Milliseconds'], example_df['X'], label='X')\n",
    "plt.plot(example_df['Milliseconds'], example_df['Y'], label='Y')\n",
    "plt.plot(example_df['Milliseconds'], example_df['Z'], label='Z')\n",
    "plt.title(\"Accelerometer Signal - Jumping (Recording 1)\")\n",
    "plt.xlabel(\"Milliseconds\")\n",
    "plt.ylabel(\"Acceleration\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "example_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332bb80",
   "metadata": {},
   "source": [
    "## üß™ Step 2: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eead4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic statistical feature extraction\n",
    "def extract_features(df):\n",
    "    \"\"\"Extracts statistical features from each sensor axis.\"\"\"\n",
    "    features = {}\n",
    "    for axis in ['X', 'Y', 'Z']:\n",
    "        data = df[axis]\n",
    "        features[f'{axis}_mean'] = np.mean(data)\n",
    "        features[f'{axis}_std'] = np.std(data)\n",
    "        features[f'{axis}_max'] = np.max(data)\n",
    "        features[f'{axis}_min'] = np.min(data)\n",
    "        features[f'{axis}_median'] = np.median(data)\n",
    "    return features\n",
    "\n",
    "# Collect features across all activities/sensors/recordings\n",
    "feature_rows = []\n",
    "\n",
    "for activity in ACTIVITIES:\n",
    "    for rec in RECORDINGS:\n",
    "        row = {'Activity': activity}\n",
    "        for sensor in SENSORS:\n",
    "            df = load_sensor_file(activity, sensor, rec)\n",
    "            feats = extract_features(df)\n",
    "            for k, v in feats.items():\n",
    "                row[f\"{sensor}_{k}\"] = v\n",
    "        feature_rows.append(row)\n",
    "\n",
    "features_df = pd.DataFrame(feature_rows)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367673db",
   "metadata": {},
   "source": [
    "## üìä Step 3: Visualize Feature Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot to visualize separability\n",
    "sns.pairplot(features_df, hue='Activity',\n",
    "             vars=[col for col in features_df.columns if 'acc_X' in col or 'gyro_X' in col])\n",
    "plt.suptitle(\"Feature Space (Subset of Features)\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5da643f",
   "metadata": {},
   "source": [
    "## ü§ñ Step 4: Train a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8365fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "X = features_df.drop(columns=['Activity'])\n",
    "y = features_df['Activity']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = knn.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e8d5b",
   "metadata": {},
   "source": [
    "## üîç Step 5: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ec1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=ACTIVITIES)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=ACTIVITIES, yticklabels=ACTIVITIES)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db068602",
   "metadata": {},
   "source": [
    "## üß™ Step 6: Test on Continuous Movement Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load continuous test file\n",
    "def load_continuous(sensor, participant=1):\n",
    "    filename = f\"run_walk_jump_pushup_{sensor}{participant}.csv\"\n",
    "    filepath = os.path.join(DATA_PATH, filename)\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['Sensor'] = sensor\n",
    "    return df\n",
    "\n",
    "# Segment continuous data into windows (e.g., every 2s ~ 200 samples)\n",
    "def sliding_window_features(sensor_data, window_size=200, step=100):\n",
    "    features = []\n",
    "    positions = []\n",
    "    for start in range(0, len(sensor_data) - window_size, step):\n",
    "        window = sensor_data.iloc[start:start+window_size]\n",
    "        feats = extract_features(window)\n",
    "        feats['Position'] = start\n",
    "        features.append(feats)\n",
    "        positions.append(start)\n",
    "    return pd.DataFrame(features), positions\n",
    "\n",
    "# Load all 3 sensors\n",
    "acc_df = load_continuous('acc')\n",
    "gyro_df = load_continuous('gyro')\n",
    "mag_df = load_continuous('mag')\n",
    "\n",
    "# Extract features from all three and merge\n",
    "acc_feats, pos = sliding_window_features(acc_df)\n",
    "gyro_feats, _ = sliding_window_features(gyro_df)\n",
    "mag_feats, _ = sliding_window_features(mag_df)\n",
    "\n",
    "combined = pd.concat([acc_feats.add_prefix(\"acc_\"), \n",
    "                      gyro_feats.add_prefix(\"gyro_\"), \n",
    "                      mag_feats.add_prefix(\"mag_\")], axis=1)\n",
    "combined['Position'] = pos\n",
    "\n",
    "# Scale using previous scaler\n",
    "X_comb = scaler.transform(combined.drop(columns='Position'))\n",
    "\n",
    "# Predict activities\n",
    "combined['Predicted'] = knn.predict(X_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefed068",
   "metadata": {},
   "source": [
    "## üìà Step 7: Visualize Classification Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b25c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions over time\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(combined['Position'], combined['Predicted'], marker='o', linestyle='-', alpha=0.7)\n",
    "plt.title(\"Predicted Activity Over Time (Continuous Recording)\")\n",
    "plt.xlabel(\"Sample Start Position (Milliseconds)\")\n",
    "plt.ylabel(\"Predicted Activity\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9044d0",
   "metadata": {},
   "source": [
    "## üß™ Optional: Try Your Own Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9342a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Uncomment to try a different model\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier(n_estimators=100)\n",
    "# clf.fit(X_train, y_train)\n",
    "# print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70cc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Time-Series Inputs for RNN\n",
    "\n",
    "# Re-load or re‚Äëderive raw windows array (X_windows) and labels (y_windows)\n",
    "# Suppose we stored them earlier as X_windows_full, y_windows_full\n",
    "# Reshape: (num_windows, time_steps, axes_count)\n",
    "# For this template, we assume we have them:\n",
    "\n",
    "# Placeholder: reshape X (flattened) back to windows of shape (num_windows, 200, 6)\n",
    "num_windows = X.shape[0]\n",
    "X_windows = X.reshape(num_windows, 200, 6)  # only valid if original flattening was consistent\n",
    "# Re-split\n",
    "Xw_train, Xw_temp, yw_train, yw_temp = train_test_split(X_windows, y, test_size=0.4, stratify=y, random_state=42)\n",
    "Xw_val, Xw_test, yw_val, yw_test = train_test_split(Xw_temp, yw_temp, test_size=0.5, stratify=yw_temp, random_state=42)\n",
    "# One-hot encode labels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "classes = sorted(list(set(y)))\n",
    "cls_to_idx = {c:i for i,c in enumerate(classes)}\n",
    "yw_train_idx = np.array([cls_to_idx[c] for c in yw_train])\n",
    "yw_val_idx = np.array([cls_to_idx[c] for c in yw_val])\n",
    "yw_test_idx = np.array([cls_to_idx[c] for c in yw_test])\n",
    "yw_train_cat = to_categorical(yw_train_idx, num_classes=len(classes))\n",
    "yw_val_cat = to_categorical(yw_val_idx, num_classes=len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b315dd0f",
   "metadata": {},
   "source": [
    "## ‚úÖ Done!\n",
    "\n",
    "You‚Äôve now:\n",
    "- Loaded and visualized raw sensor data\n",
    "- Extracted statistical features from 3-axis sensors\n",
    "- Trained a classifier to detect activity type\n",
    "- Evaluated it using a confusion matrix\n",
    "- Applied it to a continuous movement stream for testing\n",
    "- Visualized activity predictions over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
