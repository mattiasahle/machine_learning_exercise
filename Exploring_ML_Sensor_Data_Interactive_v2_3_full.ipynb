{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Machine Learning on Sensor Data ‚Äî Engineer Lab (v2.3)\n",
    "\n",
    "### üß≠ Welcome, engineer-explorer\n",
    "Today‚Äôs journey will take you from the raw pulse of sensor data to the structured intelligence of a working machine learning system. You‚Äôll clean, shape, and understand data, extract meaningful patterns, and teach algorithms to recognize behaviors ‚Äî all while reflecting on the design choices that make ML both powerful and fragile.\n",
    "\n",
    "By the end, you‚Äôll not only have built a working classifier, but also a deeper sense of what drives modern AI ‚Äî the same foundations that underpin systems like ChatGPT.\n",
    "\n",
    "Ready? Let‚Äôs build something that learns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250b53a",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Before you begin ‚Äî running this notebook\n",
    "\n",
    "This notebook is designed to work out-of-the-box on a typical developer laptop.  \n",
    "You can run it **locally in VS Code** (recommended for full control) or **online in Google Colab** (no installation required).\n",
    "\n",
    "---\n",
    "\n",
    "### üß© Option 1: Run locally in **Visual Studio Code**\n",
    "\n",
    "This gives you the best performance and flexibility if you already use VS Code.\n",
    "\n",
    "#### Step 1 ‚Äî Install prerequisites\n",
    "Make sure you have:\n",
    "- [Visual Studio Code](https://code.visualstudio.com/)\n",
    "- The **Python** and **Jupyter** extensions (search ‚ÄúJupyter‚Äù in the Extensions view)\n",
    "- [Python ‚â• 3.10](https://www.python.org/downloads/) installed and available in your PATH  \n",
    "\n",
    "‚úÖ **Linux users:**  \n",
    "Install the `venv` module (needed to create virtual environments):\n",
    "```bash\n",
    "sudo apt update\n",
    "sudo apt install python3-venv\n",
    "```\n",
    "\n",
    "Verify Python:\n",
    "```bash\n",
    "python3 --version\n",
    "```\n",
    "\n",
    "#### Step 2 ‚Äî Prepare your project folder\n",
    "Create a new folder and place these files inside:\n",
    "- `Exploring_ML_Sensor_Data_Interactive_v2_4.ipynb` (this notebook)\n",
    "- `requirements.txt`\n",
    "- your dataset folder or `data.zip`\n",
    "\n",
    "#### Step 3 ‚Äî Create and activate a virtual environment\n",
    "Open a terminal inside VS Code (``Ctrl + ` ``) and run:\n",
    "```bash\n",
    "python3 -m venv .venv\n",
    "```\n",
    "\n",
    "Activate the environment:\n",
    "\n",
    "- **Windows (PowerShell):**\n",
    "  ```powershell\n",
    "  .venv\\Scripts\\Activate\n",
    "  ```\n",
    "- **macOS / Linux:**\n",
    "  ```bash\n",
    "  source .venv/bin/activate\n",
    "  ```\n",
    "\n",
    "If the activation script is missing, install `python3-venv` as shown above and recreate the environment.\n",
    "\n",
    "#### Step 4 ‚Äî Install dependencies\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "#### Step 5 ‚Äî Tell VS Code to use this environment\n",
    "Press **Ctrl + Shift + P** ‚Üí ‚ÄúPython: Select Interpreter‚Äù ‚Üí choose the one pointing to `.venv`.\n",
    "\n",
    "#### Step 6 ‚Äî Open and run the notebook\n",
    "Open the `.ipynb` file. You‚Äôll see **Run All** or **‚ñ∂ Run Cell** buttons above each cell.  \n",
    "Run the first cell ‚Äî it should print your Python, OS, NumPy, and Pandas versions.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚òÅÔ∏è Option 2: Run online in **Google Colab**\n",
    "\n",
    "This requires no setup ‚Äî perfect if you just want to explore.\n",
    "\n",
    "1. Visit [Google Colab](https://colab.research.google.com/).  \n",
    "2. Select *File ‚Üí Upload notebook‚Ä¶* and open this file.  \n",
    "3. Upload your data archive (e.g. `data.zip`) in the *Files* sidebar.  \n",
    "4. In **Section 1**, set:\n",
    "   ```python\n",
    "   CONFIG[\"DATA_ROOT\"] = \"data.zip\"\n",
    "   ```\n",
    "5. Run all cells ‚Äî Colab already includes the required libraries.\n",
    "\n",
    "---\n",
    "\n",
    "**Tip:** Keep your notebook and dataset together.  \n",
    "Relative paths will resolve automatically, making setup faster and troubleshooting easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Environment check ‚Äî building on solid ground\n",
    "\n",
    "Before we dive into code, let‚Äôs make sure your environment is ready and connected to the notebook.  \n",
    "Machine learning depends on **reproducibility**, so even small version mismatches can cause different results.  \n",
    "This step ensures that you‚Äôre using the correct Python kernel and that your tools are aligned.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Selecting the correct kernel (VS Code)\n",
    "\n",
    "If this is your first time running a cell, VS Code will ask you to **‚ÄúSelect Kernel.‚Äù**  \n",
    "When that popup appears:\n",
    "\n",
    "1. Click **Python Environments‚Ä¶**\n",
    "2. Wait a few seconds for VS Code to list interpreters.\n",
    "3. Choose the one that ends with your project‚Äôs virtual environment, e.g.  \n",
    "   ```\n",
    "   .venv/bin/python\n",
    "   ```\n",
    "   or  \n",
    "   ```\n",
    "   Python 3.12 ('.venv': venv)\n",
    "   ```\n",
    "4. After selection, the top-right corner of VS Code should display something like:  \n",
    "   ```\n",
    "   Python 3.12 ('.venv': venv)\n",
    "   ```\n",
    "   If it takes a moment, VS Code is just installing the `ipykernel` package behind the scenes.\n",
    "\n",
    "üí° **Tip:** If no environments appear, run this once in your activated terminal and retry:\n",
    "```bash\n",
    "pip install ipykernel\n",
    "```\n",
    "\n",
    "You can confirm everything is connected by running the cell below ‚Äî it will print your Python, OS, and key library versions.\n",
    "\n",
    "---\n",
    "\n",
    "**Reflect & discuss**\n",
    "- How would you ensure consistent environments across developers or CI pipelines?\n",
    "- Why might reproducibility matter even for quick experiments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.3\n",
      "OS: Linux-6.14.0-1015-oem-x86_64-with-glibc2.39\n",
      "NumPy: 2.3.4\n",
      "Pandas: 2.3.3\n",
      "Python executable: /home/mattiaah/Github/machine_learning_exercise/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "\n",
    "# Optional: verify you're in the intended environment\n",
    "import os\n",
    "print(\"Python executable:\", sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration ‚Äî your control panel\n",
    "Every data science workflow starts with parameters ‚Äî the dials that define what, where, and how we process. By collecting these into one `CONFIG` dictionary, we make our experiments reproducible and tweakable. You can change any value and re-run downstream sections to explore cause and effect.\n",
    "\n",
    "**Knobs to tweak**\n",
    "- `WINDOW_SAMPLES` and `WINDOW_STRIDE`: define time-window size and overlap.\n",
    "- `MODELS`: pick which algorithms to benchmark.\n",
    "- `SORT_BY_TIMESTAMP`: should usually stay `True` for time-series data.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- How might overlapping windows affect independence of samples?\n",
    "- What trade-off exists between model performance and reproducibility?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "CONFIG = {\n",
    "    \"DATA_ROOT\": Path(\"data/\"),  # path to folder or .zip (e.g., \"data.zip\")\n",
    "    \"INCLUDE_GLOBS\": [\"**/*.csv\",\"**/*.parquet\",\"**/*.jsonl\",\"**/*.json\"],\n",
    "    \"SORT_BY_TIMESTAMP\": True,\n",
    "    \"WINDOW_SAMPLES\": 128,\n",
    "    \"WINDOW_STRIDE\": 128,\n",
    "    \"N_SPLITS\": 5,\n",
    "    \"RANDOM_SEED\": 42,\n",
    "    \"MODELS\": [\"knn\",\"logreg\",\"linearsvm\"],\n",
    "}\n",
    "import numpy as np\n",
    "np.random.seed(CONFIG[\"RANDOM_SEED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data ingestion ‚Äî connecting to the real world\n",
    "Machine learning begins with the raw, messy world of data. Here we unify files into a single table, attach their origins (`__source_path`), and prepare to trace results back to where they came from. This isn‚Äôt glamorous, but it‚Äôs where most ML engineering time is spent.\n",
    "\n",
    "**Knobs to tweak**\n",
    "- `CONFIG['DATA_ROOT']`: folder or zip archive containing your dataset.\n",
    "- `CONFIG['INCLUDE_GLOBS']`: file extensions or wildcards to include.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- Why is keeping track of source paths useful when debugging ML models?\n",
    "- How does this compare to data lineage tracking in production systems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def ensure_loaded_path(data_root):\n",
    "    if data_root is None:\n",
    "        return None, None\n",
    "    p = Path(data_root)\n",
    "    if p.suffix.lower()==\".zip\" and p.is_file():\n",
    "        tmp = Path(tempfile.mkdtemp(prefix=\"data_zip_\"))\n",
    "        with zipfile.ZipFile(p,\"r\") as z: z.extractall(tmp)\n",
    "        return tmp, \"zip\"\n",
    "    elif p.exists() and p.is_dir():\n",
    "        return p, \"dir\"\n",
    "    else:\n",
    "        print(\"[WARN] DATA_ROOT not found:\", data_root); return None, None\n",
    "\n",
    "def list_files(root: Path, include_globs):\n",
    "    files=[]\n",
    "    for pat in include_globs:\n",
    "        files.extend(root.glob(pat))\n",
    "    seen=set(); out=[]\n",
    "    for f in files:\n",
    "        if f.is_file() and f not in seen:\n",
    "            out.append(f); seen.add(f)\n",
    "    return out\n",
    "\n",
    "DATA_PATH, DATA_KIND = ensure_loaded_path(CONFIG[\"DATA_ROOT\"])\n",
    "if DATA_PATH is None:\n",
    "    print(\"No external data path provided; set CONFIG['DATA_ROOT'] to a folder or .zip and re-run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ax</th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "      <th>__source_path</th>\n",
       "      <th>mx</th>\n",
       "      <th>my</th>\n",
       "      <th>mz</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>gx</th>\n",
       "      <th>gy</th>\n",
       "      <th>gz</th>\n",
       "      <th>Milliseconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>501.0</td>\n",
       "      <td>1.501496</td>\n",
       "      <td>-1.197010</td>\n",
       "      <td>9.682856</td>\n",
       "      <td>cleaned/acc_mag/lie_acc1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>502.0</td>\n",
       "      <td>1.508675</td>\n",
       "      <td>-1.244866</td>\n",
       "      <td>9.699606</td>\n",
       "      <td>cleaned/acc_mag/lie_acc1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>503.0</td>\n",
       "      <td>1.487139</td>\n",
       "      <td>-1.225723</td>\n",
       "      <td>9.699606</td>\n",
       "      <td>cleaned/acc_mag/lie_acc1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504.0</td>\n",
       "      <td>1.537389</td>\n",
       "      <td>-1.259223</td>\n",
       "      <td>9.661321</td>\n",
       "      <td>cleaned/acc_mag/lie_acc1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>505.0</td>\n",
       "      <td>1.546960</td>\n",
       "      <td>-1.283151</td>\n",
       "      <td>9.745069</td>\n",
       "      <td>cleaned/acc_mag/lie_acc1.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        ax        ay        az                 __source_path  mx  \\\n",
       "0       501.0  1.501496 -1.197010  9.682856  cleaned/acc_mag/lie_acc1.csv NaN   \n",
       "1       502.0  1.508675 -1.244866  9.699606  cleaned/acc_mag/lie_acc1.csv NaN   \n",
       "2       503.0  1.487139 -1.225723  9.699606  cleaned/acc_mag/lie_acc1.csv NaN   \n",
       "3       504.0  1.537389 -1.259223  9.661321  cleaned/acc_mag/lie_acc1.csv NaN   \n",
       "4       505.0  1.546960 -1.283151  9.745069  cleaned/acc_mag/lie_acc1.csv NaN   \n",
       "\n",
       "   my  mz Timestamp   X   Y   Z  gx  gy  gz  Milliseconds  \n",
       "0 NaN NaN       NaN NaN NaN NaN NaN NaN NaN           NaN  \n",
       "1 NaN NaN       NaN NaN NaN NaN NaN NaN NaN           NaN  \n",
       "2 NaN NaN       NaN NaN NaN NaN NaN NaN NaN           NaN  \n",
       "3 NaN NaN       NaN NaN NaN NaN NaN NaN NaN           NaN  \n",
       "4 NaN NaN       NaN NaN NaN NaN NaN NaN NaN           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (377069, 16) from 204 files\n"
     ]
    }
   ],
   "source": [
    "def load_csv_robust(fp: Path):\n",
    "    import pandas as pd\n",
    "    tries=[dict(),dict(sep=\";\"),dict(sep=\"\\t\"),dict(engine=\"python\"),\n",
    "           dict(engine=\"python\",sep=\";\"),dict(engine=\"python\",sep=\"\\t\")]\n",
    "    last_e=None\n",
    "    for kw in tries:\n",
    "        try: return pd.read_csv(fp, **kw)\n",
    "        except Exception as e: last_e=e\n",
    "    raise last_e\n",
    "\n",
    "def load_tabular_file(fp: Path):\n",
    "    import pandas as pd\n",
    "    suf=fp.suffix.lower()\n",
    "    if suf==\".csv\": return load_csv_robust(fp)\n",
    "    if suf==\".parquet\":\n",
    "        try: return pd.read_parquet(fp)\n",
    "        except Exception as e: print(\"[WARN] parquet failed\", fp, e); return None\n",
    "    if suf in [\".json\",\".jsonl\"]:\n",
    "        for lines in [True, False]:\n",
    "            try: return pd.read_json(fp, lines=lines)\n",
    "            except Exception: pass\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "if DATA_PATH is not None:\n",
    "    files = list_files(DATA_PATH, CONFIG[\"INCLUDE_GLOBS\"])\n",
    "    dfs=[]\n",
    "    for f in files:\n",
    "        tdf = load_tabular_file(f)\n",
    "        if tdf is None or len(tdf)==0: continue\n",
    "        tdf = tdf.copy()\n",
    "        tdf[\"__source_path\"] = str(f.relative_to(DATA_PATH))\n",
    "        dfs.append(tdf)\n",
    "    assert dfs, \"No readable files. Verify formats.\"\n",
    "    raw = pd.concat(dfs, ignore_index=True)\n",
    "    display(raw.head())\n",
    "    print(\"Raw shape:\", raw.shape, \"from\", len(dfs), \"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Label & session derivation ‚Äî giving meaning to numbers\n",
    "Our sensors record motion, but without context they‚Äôre just numbers. Here we infer *what* each recording represents (`activity`) and *which session* it belongs to. This is how we transform raw measurements into supervised learning examples.\n",
    "\n",
    "We‚Äôll detect activity names directly from file paths (like `walk_acc6.csv` ‚Üí `walk`) and group related files using session numbers. Finally, we‚Äôll sort each file chronologically by its `Timestamp`, preserving the real-world flow of data.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- Why does chronological sorting matter for time-series problems?\n",
    "- If the same user appears in multiple sessions, what could that mean for model generalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows without activity: 110846\n",
      "Chronological sorting applied by 'Timestamp'.\n",
      "Activities: ['jump', 'run', 'sit', 'sit_to_stand', 'stand', 'stand_to_sit', 'walk']\n",
      "Sessions (groups): 6\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def derive_activity_from_path(p: str):\n",
    "    s = p.lower()\n",
    "    for token in [\"sit_to_stand\",\"stand_to_sit\",\"jump\",\"walk\",\"run\",\"sit\",\"stand\"]:\n",
    "        if token in s: return token\n",
    "    return None\n",
    "\n",
    "def derive_session_from_path(p: str):\n",
    "    stem = Path(p).stem\n",
    "    m = re.findall(r\"(\\d+)\", stem)\n",
    "    if m: return f\"session_{m[-1]}\"\n",
    "    return Path(p).parent.name or \"root\"\n",
    "\n",
    "df = raw.copy()\n",
    "df[\"activity\"] = df[\"__source_path\"].apply(derive_activity_from_path)\n",
    "df[\"group_id\"] = df[\"__source_path\"].apply(derive_session_from_path)\n",
    "before=len(df); df=df.dropna(subset=[\"activity\"]); print(\"Dropped rows without activity:\", before-len(df))\n",
    "\n",
    "if \"Unnamed: 0\" in df.columns:\n",
    "    df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "if CONFIG[\"SORT_BY_TIMESTAMP\"] and \"Timestamp\" in df.columns:\n",
    "    def robust_parse(ts):\n",
    "        try: return pd.to_datetime(ts, errors=\"coerce\", dayfirst=True)\n",
    "        except Exception: return pd.to_datetime(ts, errors=\"coerce\")\n",
    "    df[\"__ts\"] = robust_parse(df[\"Timestamp\"])\n",
    "    if df[\"__ts\"].isna().any():\n",
    "        df[\"__ts_fallback\"] = df.groupby(\"__source_path\").cumcount()\n",
    "        df[\"__ts\"] = df[\"__ts\"].fillna(pd.to_datetime(df[\"__ts_fallback\"], unit=\"s\"))\n",
    "        df = df.drop(columns=[\"__ts_fallback\"])\n",
    "    df = df.sort_values([\"__source_path\",\"__ts\"]).reset_index(drop=True)\n",
    "    print(\"Chronological sorting applied by 'Timestamp'.\")\n",
    "else:\n",
    "    print(\"No 'Timestamp' column found or sorting disabled.\")\n",
    "\n",
    "print(\"Activities:\", sorted(df[\"activity\"].unique().tolist()))\n",
    "print(\"Sessions (groups):\", df[\"group_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Sanity summaries ‚Äî knowing your battlefield\n",
    "Before extracting features, we take a strategic pause to inspect the dataset‚Äôs balance and scale. A single glance at class and session counts can save hours of confusion later.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- Which classes dominate? Which are rare?\n",
    "- How might this imbalance skew accuracy compared to macro-F1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 266223\n",
      "Per-class counts (top 10):\n",
      "activity\n",
      "jump            105132\n",
      "run              85623\n",
      "walk             50557\n",
      "sit              10453\n",
      "stand            10190\n",
      "sit_to_stand      2388\n",
      "stand_to_sit      1880\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Per-session row counts (top 10):\n",
      "group_id\n",
      "session_2    64729\n",
      "session_1    63672\n",
      "session_3    40316\n",
      "session_6    35526\n",
      "session_4    31252\n",
      "session_5    30728\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows:\", len(df))\n",
    "print(\"Per-class counts (top 10):\")\n",
    "print(df[\"activity\"].value_counts().head(10))\n",
    "print(\"\\nPer-session row counts (top 10):\")\n",
    "print(df[\"group_id\"].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Windowed features ‚Äî letting structure emerge\n",
    "\n",
    "We convert long sensor sequences into fixed-length windows and describe each window with simple statistics (mean, standard deviation, and peak-to-peak range). Different files may contain different sensors (e.g., accelerometer only vs. accelerometer+gyroscope), so we automatically keep the signals that are present in most rows and compute the summaries robustly.\n",
    "\n",
    "**Knobs to tweak**\n",
    "- `WINDOW_SAMPLES`, `WINDOW_STRIDE` ‚Äî temporal context and overlap\n",
    "- `MIN_PRESENCE` ‚Äî minimum fraction of non-missing values a column must have to be used as a signal\n",
    "\n",
    "**Reflect & discuss**\n",
    "- How does changing `WINDOW_SAMPLES` affect separability of activities?\n",
    "- What happens to metrics if you lower `MIN_PRESENCE` and include sparser sensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 signal columns (presence ‚â• 85%): [] ‚Ä¶\n",
      "Dropped (too sparse or non-numeric): ['ax', 'ay', 'az', 'mx', 'my', 'mz', 'X', 'Y', 'Z', 'gx', 'gy', 'gz'] ‚Ä¶\n",
      "Feature table: (0, 0) classes: ['jump', 'run', 'sit', 'sit_to_stand', 'stand', 'stand_to_sit', 'walk'] groups: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "# --- Config knobs for feature engineering ---\n",
    "WINDOW_SAMPLES = CONFIG[\"WINDOW_SAMPLES\"]\n",
    "WINDOW_STRIDE  = CONFIG[\"WINDOW_STRIDE\"]\n",
    "MIN_PRESENCE   = 0.85  # keep columns present (non-missing) in at least 85% of rows\n",
    "\n",
    "# --- Identify candidate sensor columns (exclude meta) ---\n",
    "meta_cols = {\"__source_path\",\"group_id\",\"activity\",\"Timestamp\",\"__ts\"}\n",
    "candidates = [c for c in df.columns if c not in meta_cols]\n",
    "\n",
    "# Coerce candidates to numeric where possible (robust against parsing quirks)\n",
    "def coerce_numeric(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        return series\n",
    "    try:\n",
    "        return pd.to_numeric(series, errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return series  # leave as-is; will be filtered out if not numeric\n",
    "\n",
    "df_clean = df.copy()\n",
    "for c in candidates:\n",
    "    df_clean[c] = coerce_numeric(df_clean[c])\n",
    "\n",
    "# Keep only numeric signals with sufficient presence across the dataset\n",
    "numeric_candidates = [c for c in candidates if pd.api.types.is_numeric_dtype(df_clean[c])]\n",
    "presence = df_clean[numeric_candidates].notna().mean().sort_values(ascending=False)\n",
    "signal_cols = [c for c in presence.index if presence[c] >= MIN_PRESENCE]\n",
    "\n",
    "print(f\"Using {len(signal_cols)} signal columns (presence ‚â• {MIN_PRESENCE:.0%}):\", signal_cols[:12], \"‚Ä¶\")\n",
    "dropped = [c for c in numeric_candidates if c not in signal_cols]\n",
    "if dropped:\n",
    "    print(\"Dropped (too sparse or non-numeric):\", dropped[:12], \"‚Ä¶\")\n",
    "\n",
    "# --- Window feature extraction ---\n",
    "def make_windows(df_in: pd.DataFrame, signal_cols, label_col, group_col, win, stride):\n",
    "    feats, labels, groups, sources = [], [], [], []\n",
    "    lab_cat = pd.Categorical(df_in[label_col])\n",
    "\n",
    "    for g, gdf in df_in.groupby(group_col, sort=False):\n",
    "        for src, sdf in gdf.groupby(\"__source_path\", sort=False):\n",
    "            sdf = sdf.reset_index(drop=True)\n",
    "            if len(sdf) < win or len(signal_cols) == 0:\n",
    "                continue\n",
    "\n",
    "            X = sdf[signal_cols].to_numpy(dtype=float)  # may include some NaNs\n",
    "            y_codes = pd.Categorical(sdf[label_col], categories=lab_cat.categories).codes\n",
    "\n",
    "            for start in range(0, len(sdf) - win + 1, stride):\n",
    "                stop = start + win\n",
    "                seg = X[start:stop]\n",
    "\n",
    "                # Majority label in the window\n",
    "                lab = pd.Series(y_codes[start:stop]).mode().iloc[0]\n",
    "\n",
    "                # Summary statistics (nan-aware)\n",
    "                mu  = np.nanmean(seg, axis=0)\n",
    "                sd  = np.nanstd(seg, axis=0, ddof=1)\n",
    "                ptp = np.nanmax(seg, axis=0) - np.nanmin(seg, axis=0)\n",
    "\n",
    "                row = {}\n",
    "                for c, v in zip(signal_cols, mu):  row[f\"{c}_mean\"] = v\n",
    "                for c, v in zip(signal_cols, sd):  row[f\"{c}_std\"]  = v\n",
    "                for c, v in zip(signal_cols, ptp): row[f\"{c}_ptp\"]  = v\n",
    "\n",
    "                feats.append(row); labels.append(lab); groups.append(g); sources.append(src)\n",
    "\n",
    "    Xf = pd.DataFrame(feats)\n",
    "    y = np.asarray(labels)\n",
    "    groups = np.asarray(groups)\n",
    "    meta = pd.DataFrame({\"group_id\": groups, \"__source_path\": sources})\n",
    "    return Xf, y, groups, meta, list(lab_cat.categories)\n",
    "\n",
    "Xf, y, groups, meta, label_names = make_windows(\n",
    "    df_clean, signal_cols, \"activity\", \"group_id\", WINDOW_SAMPLES, WINDOW_STRIDE\n",
    ")\n",
    "\n",
    "print(\"Feature table:\", Xf.shape, \"classes:\", label_names, \"groups:\", len(set(groups)))\n",
    "display(Xf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Evaluation protocol ‚Äî testing without cheating\n",
    "\n",
    "Before scoring models, we need to understand what ‚Äúfair testing‚Äù means.  \n",
    "In machine learning, *leakage* happens when information from the test set slips into training ‚Äî giving an illusion of high accuracy.  \n",
    "For time-series or session-based data, random row splits almost always leak, because adjacent samples are correlated.\n",
    "\n",
    "`GroupKFold` solves this by ensuring that **entire groups** (sessions, subjects, devices, etc.) are kept together: either in training or in testing, never both.  \n",
    "This mimics how we‚Äôd deploy a model ‚Äî to data from a *new session* it has never seen before.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- Why might random row-based splits exaggerate performance in your dataset?\n",
    "- If each session came from a different user, what would `GroupKFold` protect you from?\n",
    "- How is this idea similar to separating staging and production data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889617ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Toy example: 12 samples, 3 sessions (groups)\n",
    "X_demo = np.arange(12).reshape(-1, 1)\n",
    "y_demo = np.array(list(\"AAABBBCCCDD?\"))[:12]   # arbitrary labels\n",
    "groups_demo = np.repeat([\"session_1\", \"session_2\", \"session_3\"], 4)\n",
    "\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "folds = []\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_demo, y_demo, groups_demo), 1):\n",
    "    folds.append({\n",
    "        \"fold\": fold,\n",
    "        \"train_groups\": np.unique(groups_demo[train_idx]).tolist(),\n",
    "        \"test_groups\": np.unique(groups_demo[test_idx]).tolist()\n",
    "    })\n",
    "pd.DataFrame(folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Baseline algorithms & leaderboard ‚Äî friendly competition\n",
    "We‚Äôll compare classic algorithms using a common pipeline (Impute ‚Üí Scale ‚Üí Model). The leaderboard ranks models by macro-F1 (fair to all classes) and accuracy. Simple models like KNN and Logistic Regression often surprise us when well-prepared data is fed to them.\n",
    "\n",
    "**Knobs to tweak**\n",
    "- Add or remove models in `CONFIG['MODELS']`.\n",
    "- Tune hyperparameters (`n_neighbors`, `C`, etc.) for insight.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- What trade-offs do you notice between speed, accuracy, and interpretability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.base import clone\n",
    "import numpy as np, pandas as pd, time\n",
    "\n",
    "def build_model(name: str):\n",
    "    if name==\"knn\":       clf=KNeighborsClassifier(n_neighbors=5)\n",
    "    elif name==\"logreg\":  clf=LogisticRegression(max_iter=2000)\n",
    "    elif name==\"linearsvm\": clf=LinearSVC()\n",
    "    else: raise ValueError(name)\n",
    "    return Pipeline([(\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "                     (\"scaler\", StandardScaler()),\n",
    "                     (\"clf\", clf)])\n",
    "\n",
    "def evaluate_group_kfold(model, X, y, groups, n_splits=5):\n",
    "    g_unique = np.unique(groups)\n",
    "    n_splits = min(n_splits, len(g_unique)) if len(g_unique)>1 else 2\n",
    "    gkf=GroupKFold(n_splits=n_splits)\n",
    "    accs,f1s,fit_ms,pred_ms=[],[],[],[]\n",
    "    for tr,te in gkf.split(X,y,groups):\n",
    "        m=clone(model)\n",
    "        t0=time.time(); m.fit(X[tr],y[tr]); fit_ms.append((time.time()-t0)*1000)\n",
    "        t1=time.time(); yhat=m.predict(X[te]); pred_ms.append((time.time()-t1)*1000)\n",
    "        accs.append(accuracy_score(y[te],yhat))\n",
    "        f1s.append(f1_score(y[te],yhat,average=\"macro\"))\n",
    "    return {\"acc_mean\":float(np.mean(accs)),\"acc_std\":float(np.std(accs)),\n",
    "            \"f1_mean\":float(np.mean(f1s)),\"f1_std\":float(np.std(f1s)),\n",
    "            \"fit_ms_mean\":float(np.mean(fit_ms)),\"pred_ms_mean\":float(np.mean(pred_ms))}\n",
    "\n",
    "X_np = Xf.to_numpy(dtype=float)\n",
    "rows=[]\n",
    "for name in CONFIG[\"MODELS\"]:\n",
    "    res=evaluate_group_kfold(build_model(name), X_np, y, groups, n_splits=CONFIG[\"N_SPLITS\"])\n",
    "    res[\"model\"]=name; rows.append(res)\n",
    "leaderboard=pd.DataFrame(rows).sort_values(\"f1_mean\", ascending=False).reset_index_drop=True if hasattr(pd.DataFrame, \"reset_index_drop\") else pd.DataFrame(rows).sort_values(\"f1_mean\", ascending=False).reset_index(drop=True)\n",
    "display(leaderboard)\n",
    "best_name=leaderboard.iloc[0][\"model\"]\n",
    "print(\"Best model:\", best_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Error analysis ‚Äî facing the model‚Äôs blind spots\n",
    "Good engineers don‚Äôt just celebrate scores; they investigate mistakes. Here we inspect one session as a pseudo hold-out, viewing its confusion matrix and per-class metrics. Patterns of confusion often reveal deeper structure in both data and domain.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- Which pairs of activities are commonly confused? Why?\n",
    "- What additional features might help separate them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ug = pd.unique(groups)\n",
    "holdout = ug[-1]\n",
    "tr = groups!=holdout; te = groups==holdout\n",
    "best_model = build_model(best_name)\n",
    "best_model.fit(X_np[tr], y[tr])\n",
    "yhat = best_model.predict(X_np[te])\n",
    "print(\"Hold-out group:\", holdout, \"N:\", int(te.sum()))\n",
    "print(classification_report(y[te], yhat, digits=3))\n",
    "cm = confusion_matrix(y[te], yhat)\n",
    "plt.figure(); plt.imshow(cm, interpolation=\"nearest\")\n",
    "plt.title(\"Confusion matrix (hold-out)\"); plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\n",
    "plt.colorbar(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Class-by-session heatmap ‚Äî understanding your data‚Äôs topology\n",
    "This visualization shows which classes appear in which sessions. It helps you spot imbalances or missing combinations that may limit generalization. Think of it as a map of where your training signal comes from.\n",
    "\n",
    "**Reflect & discuss**\n",
    "- Are some classes missing from entire sessions?\n",
    "- How might this affect evaluation reliability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "tmp = pd.DataFrame({\"session\": groups, \"label\": y})\n",
    "pivot = tmp.pivot_table(index=\"session\", columns=\"label\", aggfunc=\"size\", fill_value=0)\n",
    "plt.figure(figsize=(8, max(3, len(pivot)*0.3)))\n",
    "plt.imshow(pivot, aspect=\"auto\", interpolation=\"nearest\")\n",
    "plt.title(\"Class-by-session (window counts)\")\n",
    "plt.xlabel(\"Class ID\"); plt.ylabel(\"Session\")\n",
    "plt.colorbar(label=\"count\")\n",
    "plt.yticks(ticks=range(len(pivot.index)), labels=pivot.index)\n",
    "plt.xticks(ticks=range(pivot.shape[1]), labels=range(pivot.shape[1]))\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Stretch prompts ‚Äî guided curiosity\n",
    "Now that your pipeline runs end-to-end, it‚Äôs time to experiment. Tweak, break, and observe ‚Äî this is how intuition for machine learning is built.\n",
    "\n",
    "**Try these challenges:**\n",
    "- Change `WINDOW_STRIDE` to half the window size and see how your sample count and metrics shift.\n",
    "- Tune K in KNN or `C` in Logistic Regression and observe speed vs. accuracy trade-offs.\n",
    "- Add magnitude features like `sqrt(ax¬≤ + ay¬≤ + az¬≤)` ‚Äî does it help distinguish sitting from standing?\n",
    "- Re-group sessions differently (by folder name or date) ‚Äî what happens to generalization?\n",
    "\n",
    "**Reflect & discuss**\n",
    "- Which change most improved your understanding of the system?\n",
    "- What parallels can you draw to software performance tuning or A/B testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Reflection ‚Äî from Sensor ML to Language Models\n",
    "You‚Äôve now walked through a full machine learning workflow: from messy data to a functioning classifier. What you‚Äôve done in miniature mirrors how most real-world ML systems ‚Äî including the large-scale ones like ChatGPT ‚Äî are designed.\n",
    "\n",
    "### How this exercise connects to ChatGPT\n",
    "I (ChatGPT, built by OpenAI and based on GPT‚Äë5) am also a machine learning model. Instead of learning to classify short motion windows, I predict the next token (word fragment) in a sequence of text. The foundation, however, is the same: structured data, careful evaluation, and lots of iteration.\n",
    "\n",
    "| Your workflow concept | In large-scale language models |\n",
    "|-----------------------|--------------------------------|\n",
    "| Input window of sensor samples | Window of text tokens |\n",
    "| Handcrafted features (mean/std/ptp) | Learned embeddings in neural layers |\n",
    "| Activity label | Next-token prediction target |\n",
    "| GroupKFold leakage control | Massive deduplication and held-out corpora |\n",
    "| KNN, Logistic Regression, SVM | Deep transformer network |\n",
    "| Accuracy / F1 metrics | Cross-entropy loss, perplexity |\n",
    "\n",
    "Both pipelines rest on the same principles: clean data, fair evaluation, and thoughtful iteration.\n",
    "\n",
    "### How models like me evolved from these ideas\n",
    "- **From hand-crafted to learned features:** Deep networks now discover the best representations automatically.\n",
    "- **From labeled to self-supervised data:** Instead of labels, models like me learn directly from predicting text.\n",
    "- **From small to vast scale:** The same basic loops ‚Äî forward, loss, backward ‚Äî just run on billions of parameters.\n",
    "\n",
    "### What stayed the same\n",
    "- Data quality still rules everything.\n",
    "- Separating training and evaluation remains essential.\n",
    "- Curiosity and structured experimentation ‚Äî just like what you practiced ‚Äî remain core engineering virtues.\n",
    "\n",
    "### Reflect & discuss\n",
    "- Which parts of your workflow feel universal across ML domains?\n",
    "- Where do human judgment and intuition still make the biggest impact?\n",
    "\n",
    "> *This notebook was co-created with ChatGPT (GPT-5, OpenAI), a large language model trained through the same machine learning principles you‚Äôve explored here.  \n",
    ">  \n",
    "> The starting point for this exercise was a university lab report ‚Äî a traditional academic format focusing on data cleaning and classification. Together, we transformed it into a hands-on, story-driven workshop for experienced software engineers.  \n",
    ">  \n",
    "> Mattias provided the original idea, data, and audience insight; I contributed structure, pedagogy, and modernized tooling. Step by step, we discussed how to balance intuition and rigor, how to guide exploration without overwhelming detail, and how to tie everything together with a narrative that makes machine learning *feel like an engineering journey*.  \n",
    ">  \n",
    "> What emerged from that collaboration is this notebook: a synthesis of human design and AI assistance ‚Äî built through the same iterative reasoning loop that drives great machine learning itself.  \n",
    ">  \n",
    "> The difference between this and the small models you trained is scale. The **spirit of the work**, however ‚Äî curiosity, clarity, and craftsmanship ‚Äî is exactly the same.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
