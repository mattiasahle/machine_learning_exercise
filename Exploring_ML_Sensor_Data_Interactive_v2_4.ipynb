{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "## \u2699\ufe0f Before you begin \u2014 running this notebook\n\nThis notebook is designed to work out-of-the-box on a typical developer laptop.  \nYou can run it **locally in VS Code** (recommended) or **online in Google Colab**.\n\n### \ud83e\udde9 Option 1: Run locally in **Visual Studio Code**\n\n**Step 1 \u2014 Install prerequisites**\n- Visual Studio Code\n- The Python and Jupyter extensions\n- Python \u2265 3.10\n\n**Linux users:** install the venv module:\n```bash\nsudo apt update\nsudo apt install python3-venv\n```\n\nVerify Python:\n```bash\npython3 --version\n```\n\n**Step 2 \u2014 Prepare your project folder**\n- Put this notebook, `requirements.txt`, and your dataset folder or `data.zip` in the same directory.\n\n**Step 3 \u2014 Create and activate a virtual environment**\n```bash\npython3 -m venv .venv\n# Windows (PowerShell)\n.venv\\Scripts\\Activate\n# macOS / Linux\nsource .venv/bin/activate\n```\n\nIf activation fails because `activate` is missing, install `python3-venv` and recreate the env.\n\n**Step 4 \u2014 Install dependencies**\n```bash\npip install --upgrade pip\npip install -r requirements.txt\n```\n\n**Step 5 \u2014 Select the kernel in VS Code**\nWhen prompted to **Select Kernel**, choose the interpreter that points to `.venv/bin/python`  \n(or press Ctrl+Shift+P \u2192 Python: Select Interpreter \u2192 pick `.venv`).  \nIf nothing appears, run `pip install ipykernel` in your activated env.\n\n**Step 6 \u2014 Run the notebook**\nUse **Run All** or run cells one by one.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "# Exploring Machine Learning on Sensor Data \u2014 Engineer Lab (v2.4)\n\n### \ud83e\udded Welcome, engineer-explorer\nToday\u2019s journey will take you from the raw pulse of sensor data to the structured intelligence of a working machine learning system. You'll clean, shape, and understand data, extract meaningful patterns, and teach algorithms to recognize behaviors \u2014 all while reflecting on the design choices that make ML both powerful and fragile.\n\nBy the end, you\u2019ll not only have built a working classifier, but also a deeper sense of what drives modern AI \u2014 the same foundations that underpin systems like ChatGPT.\n\nReady? Let\u2019s build something that learns.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 0) Environment check \u2014 building on solid ground\n\nBefore we dive into code, let\u2019s make sure your environment is ready and connected to the notebook.  \nThis step confirms you\u2019re using the intended Python kernel and that the core libraries are present.\n\n### \u2705 Selecting the correct kernel (VS Code)\nIf a popup asks you to **Select Kernel**:\n1. Click **Python Environments\u2026**\n2. Choose the interpreter that ends with your project\u2019s virtual environment, e.g. `.venv/bin/python`\n3. The top-right status should show `Python 3.x ('.venv': venv)`\n\nIf no environments appear, run in your terminal:\n```bash\npip install ipykernel\n```\n\n**Reflect & discuss**\n- How would you ensure consistent environments across developers or CI pipelines?\n- Why might reproducibility matter even for quick experiments?\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import sys, platform\nimport numpy as np, pandas as pd, matplotlib.pyplot as plt\n\nprint(\"Python:\", sys.version.split()[0])\nprint(\"OS:\", platform.platform())\nprint(\"NumPy:\", np.__version__)\nprint(\"Pandas:\", pd.__version__)\nprint(\"Python executable:\", sys.executable)"}, {"cell_type": "markdown", "metadata": {}, "source": "## 1) Configuration \u2014 your control panel\n\nCentralize parameters so you can tweak dials and re-run downstream steps.\n\n**Knobs to tweak**\n- `TASK`: `'movement'` (default) uses accelerometer data to classify run/walk/jump/pushup. `'static'` focuses on lie/sit/stand (acc, optional mag).\n- `WINDOW_SAMPLES`, `WINDOW_STRIDE`: temporal context & overlap\n- `N_SPLITS`: rigor of GroupKFold\n- `SORT_BY_TIMESTAMP`: keep chronological order within each file\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from pathlib import Path\nCONFIG = {\n    \"DATA_ROOT\": None,  # folder or .zip (e.g., \"data.zip\")\n    \"INCLUDE_GLOBS\": [\"**/*.csv\"],\n    \"TASK\": \"movement\",  # \"movement\" or \"static\"\n    \"USE_GYRO\": False,   # optional extension; default off to keep schema tight\n    \"SORT_BY_TIMESTAMP\": True,\n    \"WINDOW_SAMPLES\": 200,    # ~2s @100Hz, aligned with the lab report's analysis\n    \"WINDOW_STRIDE\": 200,\n    \"N_SPLITS\": 5,\n    \"RANDOM_SEED\": 42,\n    \"MODELS\": [\"knn\",\"logreg\",\"linearsvm\"],\n}\nimport numpy as np\nnp.random.seed(CONFIG[\"RANDOM_SEED\"])"}, {"cell_type": "markdown", "metadata": {}, "source": "## 2) Data ingestion \u2014 connect to the real world\n\nWe unify files into a single table and keep their origins (`__source_path`).  \nFiles come from phone sensor recordings and have **two schemas**:\n1) `Timestamp, Milliseconds, X, Y, Z` (raw export)\n2) `ax, ay, az` (and similar `gx,gy,gz`, `mx,my,mz`) with an extra `Unnamed: 0` index column\n\nWe normalize these into consistent column names based on modality inferred from the filename (`*_acc*.csv`, `*_gyro*.csv`, `*_mag*.csv`).  \nNo cross-modality merging is done here \u2014 that avoids artificial NaNs.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import zipfile, tempfile, pandas as pd, re\nfrom pathlib import Path\n\ndef ensure_loaded_path(data_root):\n    if data_root is None:\n        return None, None\n    p = Path(data_root)\n    if p.suffix.lower()==\".zip\" and p.is_file():\n        tmp = Path(tempfile.mkdtemp(prefix=\"data_zip_\"))\n        with zipfile.ZipFile(p,\"r\") as z: z.extractall(tmp)\n        return tmp, \"zip\"\n    elif p.exists() and p.is_dir():\n        return p, \"dir\"\n    else:\n        print(\"[WARN] DATA_ROOT not found:\", data_root); return None, None\n\nDATA_PATH, DATA_KIND = ensure_loaded_path(CONFIG[\"DATA_ROOT\"])\nif DATA_PATH is None:\n    print(\"No external data path provided; set CONFIG['DATA_ROOT'] to a folder or .zip and re-run.\")"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import pandas as pd\ndef read_csv_any(fp: Path):\n    tries=[dict(),dict(sep=';'),dict(sep='\\t'),dict(engine='python'),\n           dict(engine='python',sep=';'),dict(engine='python',sep='\\t')]\n    last=None\n    for kw in tries:\n        try:\n            return pd.read_csv(fp, **kw)\n        except Exception as e:\n            last=e\n    raise last\n\ndef infer_modality_from_name(name: str):\n    s = name.lower()\n    if \"gyro\" in s: return \"gyro\"\n    if \"mag\" in s:  return \"mag\"\n    if \"acc\" in s:  return \"acc\"\n    return None\n\ndef normalize_columns(df: pd.DataFrame, modality: str):\n    df = df.copy()\n    if \"Unnamed: 0\" in df.columns:\n        df = df.drop(columns=[\"Unnamed: 0\"])\n    # Map XYZ to modality-specific names if needed\n    if set([\"X\",\"Y\",\"Z\"]).issubset(df.columns):\n        if modality==\"acc\":\n            rename={\"X\":\"ax\",\"Y\":\"ay\",\"Z\":\"az\"}\n        elif modality==\"gyro\":\n            rename={\"X\":\"gx\",\"Y\":\"gy\",\"Z\":\"gz\"}\n        elif modality==\"mag\":\n            rename={\"X\":\"mx\",\"Y\":\"my\",\"Z\":\"mz\"}\n        else:\n            rename={}\n        df = df.rename(columns=rename)\n    return df\n\ndef load_manifest(root: Path, include_globs):\n    files=[]\n    for pat in include_globs:\n        files.extend(root.glob(pat))\n    out=[]\n    for f in files:\n        try:\n            tdf = read_csv_any(f)\n        except Exception as e:\n            print(\"[WARN] failed to read\", f, e); continue\n        modality = infer_modality_from_name(f.name)\n        if modality is None: \n            continue\n        tdf = normalize_columns(tdf, modality)\n        tdf[\"__source_path\"] = str(f.relative_to(root))\n        tdf[\"__modality\"] = modality\n        out.append(tdf)\n    assert out, \"No readable files.\"\n    return out\n\nif DATA_PATH is not None:\n    tables = load_manifest(DATA_PATH, CONFIG[\"INCLUDE_GLOBS\"])\n    print(\"Loaded tables:\", len(tables))\n    sample = tables[0]\n    display(sample.head())\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 3) Label & session derivation \u2014 giving meaning to numbers\n\nWe infer **activity** and **session** from file names (e.g., `walk_acc6.csv` \u2192 activity=`walk`, session=`6`).  \nWe keep files relevant to the chosen `TASK` and **sort** each file chronologically if a `Timestamp` column is present.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import pandas as pd, re\nfrom pathlib import Path\n\ndef parse_activity(pathstr: str):\n    name = Path(pathstr).name.lower()\n    for token in [\"sit_to_stand\",\"stand_to_sit\",\"pushup\",\"jump\",\"walk\",\"run\",\"sit\",\"stand\",\"lie\",\"all\"]:\n        if token in name: return token\n    return None\n\ndef parse_session(pathstr: str):\n    stem = Path(pathstr).stem\n    m = re.findall(r\"(\\d+)\", stem)\n    return m[-1] if m else \"0\"\n\ndef task_filter(activity: str, modality: str, task: str, use_gyro: bool):\n    if task==\"movement\":\n        if activity in {\"run\",\"walk\",\"jump\",\"pushup\"}:\n            if use_gyro:\n                return modality in {\"acc\",\"gyro\"}\n            else:\n                return modality==\"acc\"\n        return False\n    else: # static\n        if activity in {\"lie\",\"sit\",\"stand\"}:\n            return modality in {\"acc\",\"mag\"}\n        return False\n\n# Build one normalized long table matching the task\nframes=[]\nif DATA_PATH is not None:\n    for t in tables:\n        path = t[\"__source_path\"].iloc[0]\n        modality = t[\"__modality\"].iloc[0]\n        activity = parse_activity(path)\n        if activity is None: \n            continue\n        if not task_filter(activity, modality, CONFIG[\"TASK\"], CONFIG[\"USE_GYRO\"]):\n            continue\n        df = t.copy()\n        df[\"activity\"] = activity\n        df[\"group_id\"] = f\"session_{parse_session(path)}\"\n        # parse timestamp if present\n        if CONFIG[\"SORT_BY_TIMESTAMP\"] and \"Timestamp\" in df.columns:\n            df[\"__ts\"] = pd.to_datetime(df[\"Timestamp\"], errors=\"coerce\", dayfirst=True)\n            if df[\"__ts\"].isna().any():\n                df[\"__ts_fallback\"] = df.groupby(\"__source_path\").cumcount()\n                df[\"__ts\"] = df[\"__ts\"].fillna(pd.to_datetime(df[\"__ts_fallback\"], unit=\"s\"))\n                df = df.drop(columns=[\"__ts_fallback\"])\n            df = df.sort_values([\"__source_path\",\"__ts\"]).reset_index(drop=True)\n        frames.append(df)\n\nassert frames, \"No data matched the selected TASK.\"\nraw = pd.concat(frames, ignore_index=True)\nprint(\"Task:\", CONFIG[\"TASK\"], \"Use gyro:\", CONFIG[\"USE_GYRO\"])\nprint(\"Rows:\", len(raw), \"Columns:\", list(raw.columns)[:12])\nprint(\"Activities:\", sorted(raw['activity'].unique().tolist()))\nprint(\"Groups:\", raw['group_id'].nunique())\ndisplay(raw.head())"}, {"cell_type": "markdown", "metadata": {}, "source": "## 4) Sanity summaries \u2014 know your battlefield\n\nQuick checks on class distribution and sessions help catch issues early.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "print(\"Per-class rows:\"); display(raw['activity'].value_counts())\nprint(\"Per-session rows:\"); display(raw['group_id'].value_counts())\n\n# Check numeric signals and NaN ratio\nmeta_cols = {\"__source_path\",\"__modality\",\"activity\",\"group_id\",\"Timestamp\",\"Milliseconds\",\"__ts\"}\nnum_cols = [c for c in raw.columns if c not in meta_cols and pd.api.types.is_numeric_dtype(raw[c])]\nnan_ratio = raw[num_cols].isna().mean().sort_values(ascending=False)\nprint(\"Top 10 NaN ratios among numeric columns:\"); display(nan_ratio.head(10))"}, {"cell_type": "markdown", "metadata": {}, "source": "## 5) Windowed features \u2014 letting structure emerge\n\nWe convert sensor sequences into fixed-length windows and describe each window with simple statistics (mean, standard deviation, and peak\u2011to\u2011peak range).  \nFor **movement** we default to accelerometer-only to keep a consistent schema across all recordings. (You can enable gyroscope later as an extension.)\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import numpy as np, pandas as pd\n\nWINDOW_SAMPLES = CONFIG[\"WINDOW_SAMPLES\"]\nWINDOW_STRIDE  = CONFIG[\"WINDOW_STRIDE\"]\n\n# Choose signal columns based on task and available columns\nif CONFIG[\"TASK\"]==\"movement\":\n    signal_cols = [c for c in [\"ax\",\"ay\",\"az\"] if c in raw.columns]\nelse:\n    signal_cols = [c for c in [\"ax\",\"ay\",\"az\",\"mx\",\"my\",\"mz\"] if c in raw.columns]\n\nassert signal_cols, \"No signal columns found for the chosen task.\"\nprint(\"Using signals:\", signal_cols)\n\ndef make_windows(df_in: pd.DataFrame, signal_cols, label_col, group_col, win, stride):\n    feats, labels, groups, sources = [], [], [], []\n    lab_cat = pd.Categorical(df_in[label_col])\n    for (g, src), sdf in df_in.groupby([group_col,\"__source_path\"], sort=False):\n        sdf = sdf.reset_index(drop=True)\n        if len(sdf) < win: \n            continue\n        X = sdf[signal_cols].to_numpy(dtype=float)\n        y_codes = pd.Categorical(sdf[label_col], categories=lab_cat.categories).codes\n        for start in range(0, len(sdf)-win+1, stride):\n            stop = start + win\n            seg = X[start:stop]\n            lab = pd.Series(y_codes[start:stop]).mode().iloc[0]\n            mu  = np.nanmean(seg, axis=0)\n            sd  = np.nanstd(seg, axis=0, ddof=1)\n            ptp = np.nanmax(seg, axis=0) - np.nanmin(seg, axis=0)\n            row = {}\n            for c, v in zip(signal_cols, mu):  row[f\"{c}_mean\"]=v\n            for c, v in zip(signal_cols, sd):  row[f\"{c}_std\"] =v\n            for c, v in zip(signal_cols, ptp): row[f\"{c}_ptp\"]=v\n            feats.append(row); labels.append(lab); groups.append(g); sources.append(src)\n    Xf = pd.DataFrame(feats)\n    y = np.asarray(labels)\n    groups = np.asarray(groups)\n    meta = pd.DataFrame({\"group_id\": groups, \"__source_path\": sources})\n    return Xf, y, groups, meta, list(lab_cat.categories)\n\nXf, y, groups, meta, label_names = make_windows(raw, signal_cols, \"activity\", \"group_id\", WINDOW_SAMPLES, WINDOW_STRIDE)\nprint(\"Feature table:\", Xf.shape, \"classes:\", label_names, \"groups:\", len(set(groups)))\ndisplay(Xf.head())"}, {"cell_type": "markdown", "metadata": {}, "source": "## 6) Evaluation protocol \u2014 testing without cheating\n\nEvaluating on data that\u2019s too similar to training gives an illusion of success.  \n`GroupKFold` keeps whole sessions together: either in training or testing, never both.\n\n**Reflect & discuss**\n- Why might random row-based splits exaggerate performance here?\n- If each session came from a different user, what would `GroupKFold` protect you from?\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "# Small demo to show how GroupKFold splits by session\nfrom sklearn.model_selection import GroupKFold\nimport numpy as np, pandas as pd\n\ndemo_groups = np.array([\"s1\",\"s1\",\"s1\",\"s2\",\"s2\",\"s2\",\"s3\",\"s3\",\"s3\"])\ndemo_X = np.arange(len(demo_groups)).reshape(-1,1)\ngkf = GroupKFold(n_splits=3)\n\nfolds=[]\nfor i,(tr,te) in enumerate(gkf.split(demo_X, groups=demo_groups),1):\n    folds.append({\"fold\":i,\n                  \"train_groups\":np.unique(demo_groups[tr]).tolist(),\n                  \"test_groups\":np.unique(demo_groups[te]).tolist()})\npd.DataFrame(folds)"}, {"cell_type": "markdown", "metadata": {}, "source": "## 7) Baseline algorithms & leaderboard \u2014 friendly competition\n\nWe compare classic algorithms using a common pipeline (Impute \u2192 Scale \u2192 Model).  \nLeaderboard ranks by macro\u2011F1 and accuracy.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.base import clone\nimport numpy as np, pandas as pd, time\n\ndef build_model(name: str):\n    if name==\"knn\":       clf=KNeighborsClassifier(n_neighbors=5)\n    elif name==\"logreg\":  clf=LogisticRegression(max_iter=2000)\n    elif name==\"linearsvm\": clf=LinearSVC()\n    else: raise ValueError(name)\n    return Pipeline([(\"impute\", SimpleImputer(strategy=\"median\")),\n                     (\"scaler\", StandardScaler()),\n                     (\"clf\", clf)])\n\ndef evaluate_group_kfold(model, X, y, groups, n_splits=5):\n    g_unique = np.unique(groups)\n    n_splits = min(n_splits, len(g_unique)) if len(g_unique)>1 else 2\n    gkf=GroupKFold(n_splits=n_splits)\n    accs,f1s,fit_ms,pred_ms=[],[],[],[]\n    for tr,te in gkf.split(X,y,groups):\n        m=clone(model)\n        t0=time.time(); m.fit(X[tr],y[tr]); fit_ms.append((time.time()-t0)*1000)\n        t1=time.time(); yhat=m.predict(X[te]); pred_ms.append((time.time()-t1)*1000)\n        accs.append(accuracy_score(y[te],yhat))\n        f1s.append(f1_score(y[te],yhat,average=\"macro\"))\n    return {\"acc_mean\":float(np.mean(accs)),\"acc_std\":float(np.std(accs)),\n            \"f1_mean\":float(np.mean(f1s)),\"f1_std\":float(np.std(f1s)),\n            \"fit_ms_mean\":float(np.mean(fit_ms)),\"pred_ms_mean\":float(np.mean(pred_ms))}\n\nX_np = Xf.to_numpy(dtype=float)\nrows=[]\nfor name in CONFIG[\"MODELS\"]:\n    res=evaluate_group_kfold(build_model(name), X_np, y, groups, n_splits=CONFIG[\"N_SPLITS\"])\n    res[\"model\"]=name; rows.append(res)\nleaderboard=pd.DataFrame(rows).sort_values(\"f1_mean\", ascending=False).reset_index(drop=True)\ndisplay(leaderboard)\nbest_name=leaderboard.iloc[0][\"model\"]\nprint(\"Best model:\", best_name)"}, {"cell_type": "markdown", "metadata": {}, "source": "## 8) Error analysis \u2014 facing the model\u2019s blind spots\n\nWe pick one session as a pseudo hold\u2011out for inspection and view per\u2011class errors.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "from sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nug = pd.unique(groups)\nholdout = ug[-1]\ntr = groups!=holdout; te = groups==holdout\nbest_model = build_model(best_name)\nbest_model.fit(X_np[tr], y[tr])\nyhat = best_model.predict(X_np[te])\nprint(\"Hold-out group:\", holdout, \"N:\", int(te.sum()))\nprint(classification_report(y[te], yhat, digits=3))\ncm = confusion_matrix(y[te], yhat)\nplt.figure(); plt.imshow(cm, interpolation=\"nearest\")\nplt.title(\"Confusion matrix (hold-out)\"); plt.xlabel(\"Pred\"); plt.ylabel(\"True\")\nplt.colorbar(); plt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## 9) Class\u2011by\u2011session heatmap \u2014 understand your data\u2019s topology\n\nSee which classes appear in which sessions to reason about split difficulty and metric reliability.\n"}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": "import pandas as pd, numpy as np, matplotlib.pyplot as plt\ntmp = pd.DataFrame({\"session\": groups, \"label\": y})\npivot = tmp.pivot_table(index=\"session\", columns=\"label\", aggfunc=\"size\", fill_value=0)\nplt.figure(figsize=(8, max(3, len(pivot)*0.3)))\nplt.imshow(pivot, aspect=\"auto\", interpolation=\"nearest\")\nplt.title(\"Class-by-session (window counts)\")\nplt.xlabel(\"Class ID\"); plt.ylabel(\"Session\")\nplt.colorbar(label=\"count\")\nplt.yticks(ticks=range(len(pivot.index)), labels=pivot.index)\nplt.xticks(ticks=range(pivot.shape[1]), labels=range(pivot.shape[1]))\nplt.tight_layout(); plt.show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## 10) Stretch prompts \u2014 guided curiosity\n\n- Set `WINDOW_STRIDE = WINDOW_SAMPLES // 2` and re-run sections 5\u21929. What changed and why?\n- Toggle `USE_GYRO=True` and attempt feature fusion (accelerometer + gyroscope) \u2014 how do metrics move?\n- Add magnitude features: `sqrt(ax^2 + ay^2 + az^2)` \u2014 do they help with run vs walk?\n- Re-group sessions (by parent folder) \u2014 what happens to generalization?\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## 11) Reflection \u2014 from Sensor ML to Language Models\n\nYou\u2019ve now walked through a full machine learning workflow: from messy data to a functioning classifier. What you\u2019ve done in miniature mirrors how most real-world ML systems \u2014 including ChatGPT \u2014 are designed.\n\n### How this exercise connects to ChatGPT\nI (ChatGPT, built by OpenAI and based on GPT\u20115) am also a machine learning model. Instead of learning to classify motion windows, I predict the next token in a sequence of text. The foundation is the same: structured data, careful evaluation, and iteration.\n\n| Your workflow concept | In large\u2011scale language models |\n|---|---|\n| Input window of sensor samples | Window of text tokens |\n| Handcrafted features (mean/std/ptp) | Learned embeddings in neural layers |\n| Activity label | Next\u2011token prediction target |\n| GroupKFold leakage control | Deduplication and held\u2011out corpora |\n| KNN, Logistic Regression, SVM | Deep transformer network |\n| Accuracy / F1 metrics | Cross\u2011entropy loss, perplexity |\n\n### How models like me evolved from these ideas\n- **From hand\u2011crafted to learned features:** neural networks discover useful representations automatically.  \n- **From labeled to self\u2011supervised data:** train by predicting text itself.  \n- **From small to vast scale:** same training loop, many more parameters.\n\n### What stayed the same\n- Data quality still rules everything.  \n- Separation of training and evaluation remains essential.  \n- Curiosity and structured experimentation \u2014 just like what you practiced \u2014 remain core engineering virtues.\n\n> *This notebook was co\u2011created with ChatGPT (GPT\u20115, OpenAI), inspired by an earlier university lab report from Mattias. We started from that academic exercise and, through your guidance, evolved it into a hands\u2011on, story\u2011driven workshop for experienced engineers: we modernized the tooling, clarified evaluation with GroupKFold, tightened the feature schema to avoid modality mixing (and the NaN cascade), and added a narrative thread that links classical ML to contemporary AI. The difference from the models you trained today is scale; the craftsmanship is shared.*\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}